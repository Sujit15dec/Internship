{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "833ae767",
   "metadata": {},
   "source": [
    "# Web Scraping Assignment-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c86bd8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List all the header tags :\n",
      "\n",
      "<h1 class=\"firstHeading\" id=\"firstHeading\">Main Page</h1>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfa-h2\"><span id=\"From_today.27s_featured_article\"></span><span class=\"mw-headline\" id=\"From_today's_featured_article\">From today's featured article</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-dyk-h2\"><span class=\"mw-headline\" id=\"Did_you_know_...\">Did you know ...</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-itn-h2\"><span class=\"mw-headline\" id=\"In_the_news\">In the news</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-otd-h2\"><span class=\"mw-headline\" id=\"On_this_day\">On this day</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-tfp-h2\"><span id=\"Today.27s_featured_picture\"></span><span class=\"mw-headline\" id=\"Today's_featured_picture\">Today's featured picture</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-other\"><span class=\"mw-headline\" id=\"Other_areas_of_Wikipedia\">Other areas of Wikipedia</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-sister\"><span id=\"Wikipedia.27s_sister_projects\"></span><span class=\"mw-headline\" id=\"Wikipedia's_sister_projects\">Wikipedia's sister projects</span></h2>\n",
      "\n",
      "<h2 class=\"mp-h2\" id=\"mp-lang\"><span class=\"mw-headline\" id=\"Wikipedia_languages\">Wikipedia languages</span></h2>\n",
      "\n",
      "<h2>Navigation menu</h2>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-personal-label\">\n",
      "<span>Personal tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-namespaces-label\">\n",
      "<span>Namespaces</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"Change language variant\" class=\"vector-menu-heading\" id=\"p-variants-label\">\n",
      "<span>Variants</span>\n",
      "<span class=\"vector-menu-checkbox-expanded\">expanded</span>\n",
      "<span class=\"vector-menu-checkbox-collapsed\">collapsed</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-views-label\">\n",
      "<span>Views</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-cactions-label\">\n",
      "<span>More</span>\n",
      "<span class=\"vector-menu-checkbox-expanded\">expanded</span>\n",
      "<span class=\"vector-menu-checkbox-collapsed\">collapsed</span>\n",
      "</h3>\n",
      "\n",
      "<h3>\n",
      "<label for=\"searchInput\">Search</label>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-navigation-label\">\n",
      "<span>Navigation</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-interaction-label\">\n",
      "<span>Contribute</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-tb-label\">\n",
      "<span>Tools</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-coll-print_export-label\">\n",
      "<span>Print/export</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-wikibase-otherprojects-label\">\n",
      "<span>In other projects</span>\n",
      "</h3>\n",
      "\n",
      "<h3 aria-label=\"\" class=\"vector-menu-heading\" id=\"p-lang-label\">\n",
      "<span>Languages</span>\n",
      "</h3>\n"
     ]
    }
   ],
   "source": [
    "#Q1 Write a python program to display all the header tags from‘en.wikipedia.org/wiki/Main_Page’\n",
    "\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "html = urlopen('https://en.wikipedia.org/wiki/Main_Page')\n",
    "bs = BeautifulSoup(html, \"html.parser\")\n",
    "titles = bs.find_all(['h1', 'h2','h3','h4','h5','h6'])\n",
    "print('List all the header tags :', *titles, sep='\\n\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d5c65993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>IMDB_Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Once Upon a Time in the West</td>\n",
       "      <td>(1968)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Psycho</td>\n",
       "      <td>(1960)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Rear Window</td>\n",
       "      <td>(1954)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Casablanca</td>\n",
       "      <td>(1942)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Modern Times</td>\n",
       "      <td>(1936)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Movie    Year  IMDB_Rating\n",
       "0       The Shawshank Redemption  (1994)          9.3\n",
       "1                  The Godfather  (1972)          9.2\n",
       "2                The Dark Knight  (2008)          9.0\n",
       "3         The Godfather: Part II  (1974)          9.0\n",
       "4                   12 Angry Men  (1957)          9.0\n",
       "..                           ...     ...          ...\n",
       "95  Once Upon a Time in the West  (1968)          8.5\n",
       "96                        Psycho  (1960)          8.5\n",
       "97                   Rear Window  (1954)          8.5\n",
       "98                    Casablanca  (1942)          8.5\n",
       "99                  Modern Times  (1936)          8.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2 Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from time import sleep\n",
    "from random import randint\n",
    "\n",
    "# Creating the lists we want to write into\n",
    "titles = []\n",
    "years = []\n",
    "imdb_ratings = []\n",
    "\n",
    "# Getting English translated titles from the movies\n",
    "headers = {'Accept-Language': 'en-US, en;q=0.5'}\n",
    "\n",
    "pages = np.arange(0, 200, 100)\n",
    "pages\n",
    "\n",
    "# urls of 100 movies \n",
    "for page in pages:\n",
    "    # Getting the contents from the url\n",
    "    page = requests.get('https://www.imdb.com/search/title/?groups=top_100&sort=user_rating,desc=' + str(page) + '&ref_=adv_nxt', headers=headers)\n",
    "    soup = BeautifulSoup(page.text, 'html.parser')\n",
    "    \n",
    "    # Aiming the part of the html we want to get the information from\n",
    "    movie_div = soup.find_all('div', class_='lister-item mode-advanced')\n",
    "    \n",
    "    # Controling the loop’s rate by pausing the execution of the loop for a specified amount of time\n",
    "    # Waiting time between requests for a number between 2-10 seconds\n",
    "    sleep(randint(2,10))\n",
    "    \n",
    "    \n",
    "    for container in movie_div:\n",
    "        # Scraping the movie's name\n",
    "        name = container.h3.a.text\n",
    "        titles.append(name)\n",
    "        \n",
    "        # Scraping the movie's year\n",
    "        year = container.h3.find('span', class_='lister-item-year').text\n",
    "        years.append(year)\n",
    "        \n",
    "        # Scraping the rating\n",
    "        imdb = float(container.strong.text)\n",
    "        imdb_ratings.append(imdb)\n",
    "       \n",
    "      \n",
    "        movies = pd.DataFrame({'Movie':titles,'Year':years,'IMDB_Rating':imdb_ratings,})\n",
    "\n",
    "movies.head()\n",
    "\n",
    "movies.dtypes\n",
    "\n",
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fcf0a5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Year</th>\n",
       "      <th>IMDB rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.Rang De Basanti(2006)</td>\n",
       "      <td>(2006)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.3 Idiots(2009)</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.Taare Zameen Par(2007)</td>\n",
       "      <td>(2007)</td>\n",
       "      <td>8.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.Dil Chahta Hai(2001)</td>\n",
       "      <td>(2001)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.Swades: We, the People(2004)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96.Wake Up Sid(2009)</td>\n",
       "      <td>(2009)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97.Rangeela(1995)</td>\n",
       "      <td>(1995)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98.Shatranj Ke Khilari(1977)</td>\n",
       "      <td>(1977)</td>\n",
       "      <td>7.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99.Pyaar Ka Punchnama(2011)</td>\n",
       "      <td>(2011)</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100.Ek Hasina Thi(2004)</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Movie    Year IMDB rating\n",
       "0          1.Rang De Basanti(2006)  (2006)         8.1\n",
       "1                 2.3 Idiots(2009)  (2009)         8.4\n",
       "2         3.Taare Zameen Par(2007)  (2007)         8.4\n",
       "3           4.Dil Chahta Hai(2001)  (2001)         8.1\n",
       "4   5.Swades: We, the People(2004)  (2004)         8.2\n",
       "..                             ...     ...         ...\n",
       "95            96.Wake Up Sid(2009)  (2009)         7.6\n",
       "96               97.Rangeela(1995)  (1995)         7.5\n",
       "97    98.Shatranj Ke Khilari(1977)  (1977)         7.7\n",
       "98     99.Pyaar Ka Punchnama(2011)  (2011)         7.6\n",
       "99         100.Ek Hasina Thi(2004)  (2004)         7.5\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3 Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and make data frame.\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from requests import get\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "source = 'https://www.imdb.com/list/ls009997493/'\n",
    "\n",
    "r = requests.get(source)\n",
    "htmlContent= r.content\n",
    "soup= BeautifulSoup(htmlContent,'html.parser')\n",
    "\n",
    "titles = []\n",
    "for i in soup.find_all(\"h3\", class_=\"lister-item-header\"):\n",
    "    titles.append(i.text.replace('\\n',''))\n",
    "\n",
    "    \n",
    "years = []\n",
    "for i in soup.find_all(\"span\", class_=\"lister-item-year\"):\n",
    "    years.append(i.text)\n",
    "    \n",
    "movies = soup.find_all ('div',class_='lister-item-content')\n",
    "\n",
    "IDBM_rating = []\n",
    "for i in movies:\n",
    "    IDBM_rating.append(i.find('span',class_='ipl-rating-star__rating').text)\n",
    "    \n",
    "IDBM_rating\n",
    "\n",
    "(len(titles),len(years),len(IDBM_rating))\n",
    "\n",
    "df = pd.DataFrame({'Movie':titles,'Year':years,'IMDB rating':IDBM_rating})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c278c141",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>32</td>\n",
       "      <td>3,793</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>28</td>\n",
       "      <td>3,244</td>\n",
       "      <td>116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>32</td>\n",
       "      <td>3,624</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>25</td>\n",
       "      <td>2,459</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>27</td>\n",
       "      <td>2,524</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>30</td>\n",
       "      <td>2,740</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>30</td>\n",
       "      <td>2,523</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>32</td>\n",
       "      <td>2,657</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>1,054</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0   New Zealand      17  2,054   \n",
       "1       England      32  3,793   \n",
       "2     Australia      28  3,244   \n",
       "3         India      32  3,624   \n",
       "4  South Africa      25  2,459   \n",
       "5      Pakistan      27  2,524   \n",
       "6    Bangladesh      30  2,740   \n",
       "7   West Indies      30  2,523   \n",
       "8     Sri Lanka      32  2,657   \n",
       "9   Afghanistan      17  1,054   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              121               ...  \n",
       "1                                                119  \n",
       "2                                                116  \n",
       "3                                                113  \n",
       "4                                                 98  \n",
       "5                                                 93  \n",
       "6                                                 91  \n",
       "7                                                 84  \n",
       "8                                                 83  \n",
       "9                                                 62  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "#i) Top 10 ODI teams in men’s cricket along with the records for matches, points andrating \n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c919359f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Batsmen Team Ratings\n",
       "0      Virat Kohli  IND     844\n",
       "1     Rohit Sharma  IND     813\n",
       "2      Ross Taylor   NZ     801\n",
       "3      Aaron Finch  AUS     779\n",
       "4   Jonny Bairstow  ENG     775\n",
       "5     David Warner  AUS     762\n",
       "6        Shai Hope   WI     758\n",
       "7  Kane Williamson   NZ     754\n",
       "8  Quinton de Kock   SA     747\n",
       "9     Fakhar Zaman  PAK     741"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 ii) Top 10 ODI Batsmen in men along with the records of their team and ratin\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "page5 = requests.get(url)\n",
    "\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "batsmen = [] #empty list\n",
    "team = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    batsmen.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell nationality-logo rankings-table__team'):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "\n",
    "    \n",
    "# Make data frame of Top 10 ODI Batsmen\n",
    "icc=pd.DataFrame({})\n",
    "icc['Batsmen']=batsmen[:10]\n",
    "icc['Team']=team[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e48848cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bowler</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Mitchell Starc</td>\n",
       "      <td>AUS</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Shakib Al Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Bowler Team Ratings\n",
       "0     Josh Hazlewood  AUS     709\n",
       "1   Mujeeb Ur Rahman  AFG     708\n",
       "2       Chris Woakes  ENG     700\n",
       "3       Mehedi Hasan  BAN     692\n",
       "4         Matt Henry   NZ     691\n",
       "5     Jasprit Bumrah  IND     679\n",
       "6     Mitchell Starc  AUS     652\n",
       "7    Shakib Al Hasan  BAN     650\n",
       "8      Kagiso Rabada   SA     646\n",
       "9  Mustafizur Rahman  BAN     640"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4 iii) Top 10 ODI bowlers along with the records of their team andrating.\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "page5 = requests.get(url)\n",
    "\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "bowlers = [] #empty list\n",
    "team = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    bowlers.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell nationality-logo rankings-table__team'):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "\n",
    "    \n",
    "# Make data frame of Top 10 ODI Batsmen\n",
    "icc=pd.DataFrame({})\n",
    "icc['Bowler']=bowlers[:10]\n",
    "icc['Team']=team[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23559e05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Team_name</th>\n",
       "      <th>Matches</th>\n",
       "      <th>Points</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>21</td>\n",
       "      <td>3,379</td>\n",
       "      <td>161               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>England</td>\n",
       "      <td>25</td>\n",
       "      <td>2,983</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>29</td>\n",
       "      <td>3,390</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>26</td>\n",
       "      <td>2,934</td>\n",
       "      <td>113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>26</td>\n",
       "      <td>2,392</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>22</td>\n",
       "      <td>1,872</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>20</td>\n",
       "      <td>1,496</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Team_name Matches Points  \\\n",
       "0     Australia      21  3,379   \n",
       "1       England      25  2,983   \n",
       "2  South Africa      29  3,390   \n",
       "3         India      26  2,934   \n",
       "4   New Zealand      26  2,392   \n",
       "5   West Indies      22  1,872   \n",
       "6      Pakistan      20  1,496   \n",
       "7    Bangladesh       5    306   \n",
       "8     Sri Lanka      11    519   \n",
       "9       Ireland       2     25   \n",
       "\n",
       "                                             Ratings  \n",
       "0                              161               ...  \n",
       "1                                                119  \n",
       "2                                                117  \n",
       "3                                                113  \n",
       "4                                                 92  \n",
       "5                                                 85  \n",
       "6                                                 75  \n",
       "7                                                 61  \n",
       "8                                                 47  \n",
       "9                                                 13  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have toscrape:\n",
    "#i) Top 10 ODI teams in women’s cricket along with the records for matches, points andrating.\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/team-rankings/odi\"\n",
    "page5 = requests.get(url)\n",
    "# see content in page5\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "\n",
    "#scrape team names\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "matches = [] #empty list\n",
    "points = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--matches'): # first place team number of matches\n",
    "    matches.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--points'):# first place team points\n",
    "    points.append(i.text)\n",
    "for i in soup5.find_all(\"td\",class_='rankings-block__banner--rating u-text-right'):# first place team ratings\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "    \n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-center-text'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell u-text-right rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "\n",
    "# Make data frame of top 10 ICC teams\n",
    "icc=pd.DataFrame({})\n",
    "icc['Team_name']=team_name[:10]\n",
    "icc['Matches']=matches[:10]\n",
    "icc['Points']=points[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73a5c255",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batsmen_Women</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Beth Mooney</td>\n",
       "      <td>AUS</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Heather Knight</td>\n",
       "      <td>ENG</td>\n",
       "      <td>674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rachael Haynes</td>\n",
       "      <td>AUS</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Batsmen_Women Team Ratings\n",
       "0       Alyssa Healy  AUS     750\n",
       "1        Mithali Raj  IND     738\n",
       "2     Tammy Beaumont  ENG     728\n",
       "3  Amy Satterthwaite   NZ     717\n",
       "4    Smriti Mandhana  IND     710\n",
       "5        Meg Lanning  AUS     699\n",
       "6        Beth Mooney  AUS     690\n",
       "7     Heather Knight  ENG     674\n",
       "8    Laura Wolvaardt   SA     672\n",
       "9     Rachael Haynes  AUS     668"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\"\n",
    "page5 = requests.get(url)\n",
    "\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "batsmen = [] #empty list\n",
    "team = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    batsmen.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell nationality-logo rankings-table__team'):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell table-head__cell--rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of Top 10 women’s ODI players\n",
    "icc=pd.DataFrame({})\n",
    "icc['Batsmen_Women']=batsmen[:10]\n",
    "icc['Team']=team[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b699b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>All_Rounder</th>\n",
       "      <th>Team</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jhulan Goswami</td>\n",
       "      <td>IND</td>\n",
       "      <td>251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        All_Rounder Team Ratings\n",
       "0    Natalie Sciver  ENG     372\n",
       "1      Ellyse Perry  AUS     365\n",
       "2   Stafanie Taylor   WI     322\n",
       "3     Deepti Sharma  IND     299\n",
       "4  Ashleigh Gardner  AUS     275\n",
       "5  Dane van Niekerk   SA     274\n",
       "6     Jess Jonassen  AUS     272\n",
       "7   Katherine Brunt  ENG     272\n",
       "8    Jhulan Goswami  IND     251\n",
       "9     Sophie Devine   NZ     248"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q5 iii) Top 10 women’s ODI all-rounder along with the records of their team andrating.\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\"\n",
    "page5 = requests.get(url)\n",
    "\n",
    "soup5 = BeautifulSoup(page5.content)\n",
    "\n",
    "team = soup5.find_all(\"span\",class_='u-hide-phablet')\n",
    "team_name = []\n",
    "for i in team:\n",
    "    team_name.append(i.text)\n",
    "    \n",
    "all_rounder = [] #empty list\n",
    "team = [] #empty list\n",
    "ratings = [] #empty list\n",
    "new_list = [] #empty list\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rankings-table__name name'):\n",
    "    all_rounder.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell nationality-logo rankings-table__team'):\n",
    "    team.append(i.text.replace(\"\\n\",\"\"))\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell rating'):\n",
    "    ratings.append(i.text.replace(\"\\n\",\"\"))\n",
    "\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell'):# other teams number of matches and points\n",
    "    new_list.append(i.text)\n",
    "for i in range(0,len(new_list)-1,2):\n",
    "    matches.append(new_list[i]) # other teams matches\n",
    "    points.append(new_list[i+1]) # other teams points\n",
    "for i in soup5.find_all(\"td\",class_='table-body__cell table-head__cell--rating'):# other teams ratings\n",
    "    ratings.append(i.text)\n",
    "    \n",
    "# Make data frame of Top 10 women’s ODI players\n",
    "icc=pd.DataFrame({})\n",
    "icc['All_Rounder']=all_rounder[:10]\n",
    "icc['Team']=team[:10]\n",
    "icc['Ratings']=ratings[:10]\n",
    "icc  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb9b1213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q6. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "page = requests.get('https://www.amazon.in/s?k=smartphone+under+20000&rh=n%3A976419031%2Cp_36%3A1318506031&dc&qid=1631345642&rnid=1318502031&ref=sr_nr_p_36_4')\n",
    "soup=BeautifulSoup(page.content)\n",
    "page\n",
    "\n",
    "#here is a problem with amezon website its always shows \"Response [503]\" untill change the kernel after change the kernel its shows that \"Response [200]\" after that my codes works for scraping the data from Amezon "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "825a7682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Images_url</th>\n",
       "      <th>Raring</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>OPPO A74 5G (Fluid Black,6GB RAM,128GB Storage...</td>\n",
       "      <td>15,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71poFSdDs5...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OPPO A31 (Mystery Black, 6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,490</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71KCwNV6Mu...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...</td>\n",
       "      <td>15,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71-Su4Wr0H...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Redmi Note 10 Pro (Dark Night, 6GB RAM, 128GB ...</td>\n",
       "      <td>17,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81S-XYJlzT...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Redmi Note 10S (Deep Sea Blue, 6GB RAM, 64GB S...</td>\n",
       "      <td>13,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81B0HJigO-...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Samsung Galaxy M32 5G (Sky Blue, 8GB RAM, 128G...</td>\n",
       "      <td>18,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71os5DRhuS...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>OPPO A74 5G (Fantastic Purple,6GB RAM,128GB St...</td>\n",
       "      <td>15,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71geVdy6-O...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Samsung Galaxy M32 5G (Sky Blue, 6GB RAM, 128G...</td>\n",
       "      <td>16,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71os5DRhuS...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>realme narzo 30 (Racing Blue, 6GB RAM, 128GB S...</td>\n",
       "      <td>15,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/719tm7l723...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>iQOO Z3 5G (Cyber Blue, 6GB RAM, 128GB Storage)</td>\n",
       "      <td>17,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/615CXlFtDD...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Samsung Galaxy M32 (Light Blue, 6GB RAM, 128GB...</td>\n",
       "      <td>14,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71F4jU7MRU...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...</td>\n",
       "      <td>11,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71r69Y7BSe...</td>\n",
       "      <td>4.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Samsung Galaxy M32 5G (Slate Black, 6GB RAM, 1...</td>\n",
       "      <td>16,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71QT7dSK4B...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Vivo Y12s (Phantom Black, 3GB, 32GB ) with No ...</td>\n",
       "      <td>10,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71UAi2jwsN...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>iQOO Z3 5G (Ace Black, 6GB RAM, 128GB Storage)</td>\n",
       "      <td>17,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61uIgwiP90...</td>\n",
       "      <td>4.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Samsung Galaxy M32 (Black, 4GB RAM, 64GB Stora...</td>\n",
       "      <td>12,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71Q3iSQAwA...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Vivo Y21 (Diamond Glow, 4GB RAM, 64GB Storage)...</td>\n",
       "      <td>13,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/51GkJLzb9N...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Samsung Galaxy M51 (Celestial Black, 6GB RAM, ...</td>\n",
       "      <td>19,999</td>\n",
       "      <td>https://m.media-amazon.com/images/I/713AhSUtbH...</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>realme narzo 50A (Oxygen Green, 4GB RAM + 128G...</td>\n",
       "      <td>12,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/718CklLKXm...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Vivo Y12s (Glacier Blue, 3GB, 32GB ) with No C...</td>\n",
       "      <td>10,990</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71MeL149KB...</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>realme narzo 50A (Oxygen Blue, 4GB RAM + 128GB...</td>\n",
       "      <td>12,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/71hgVYiuFX...</td>\n",
       "      <td>3.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Redmi 10 Prime (Bifrost Blue 6GB RAM 128GB ROM</td>\n",
       "      <td>14,499</td>\n",
       "      <td>https://m.media-amazon.com/images/I/81di9YjMe-...</td>\n",
       "      <td>3.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Realme C25Y (Metal Grey, 4GB RAM, 128GB Storag...</td>\n",
       "      <td>11,648</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41+r5uIAAA...</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Product_name   Price  \\\n",
       "0   OPPO A74 5G (Fluid Black,6GB RAM,128GB Storage...  15,990   \n",
       "1   OPPO A31 (Mystery Black, 6GB RAM, 128GB Storag...  11,490   \n",
       "2   Samsung Galaxy M31 (Ocean Blue, 8GB RAM, 128GB...  15,999   \n",
       "3   Redmi Note 10 Pro (Dark Night, 6GB RAM, 128GB ...  17,999   \n",
       "4   Redmi Note 10S (Deep Sea Blue, 6GB RAM, 64GB S...  13,999   \n",
       "5   Samsung Galaxy M32 5G (Sky Blue, 8GB RAM, 128G...  18,999   \n",
       "6   OPPO A74 5G (Fantastic Purple,6GB RAM,128GB St...  15,990   \n",
       "7   Samsung Galaxy M32 5G (Sky Blue, 6GB RAM, 128G...  16,999   \n",
       "8   realme narzo 30 (Racing Blue, 6GB RAM, 128GB S...  15,499   \n",
       "9    iQOO Z3 5G (Cyber Blue, 6GB RAM, 128GB Storage)   17,990   \n",
       "10  Samsung Galaxy M32 (Light Blue, 6GB RAM, 128GB...  14,999   \n",
       "11  Samsung Galaxy M12 (Blue,6GB RAM, 128GB Storag...  11,499   \n",
       "12  Samsung Galaxy M32 5G (Slate Black, 6GB RAM, 1...  16,999   \n",
       "13  Vivo Y12s (Phantom Black, 3GB, 32GB ) with No ...  10,990   \n",
       "14    iQOO Z3 5G (Ace Black, 6GB RAM, 128GB Storage)   17,990   \n",
       "15  Samsung Galaxy M32 (Black, 4GB RAM, 64GB Stora...  12,999   \n",
       "16  Vivo Y21 (Diamond Glow, 4GB RAM, 64GB Storage)...  13,990   \n",
       "17  Samsung Galaxy M51 (Celestial Black, 6GB RAM, ...  19,999   \n",
       "18  realme narzo 50A (Oxygen Green, 4GB RAM + 128G...  12,499   \n",
       "19  Vivo Y12s (Glacier Blue, 3GB, 32GB ) with No C...  10,990   \n",
       "20  realme narzo 50A (Oxygen Blue, 4GB RAM + 128GB...  12,499   \n",
       "21    Redmi 10 Prime (Bifrost Blue 6GB RAM 128GB ROM   14,499   \n",
       "22  Realme C25Y (Metal Grey, 4GB RAM, 128GB Storag...  11,648   \n",
       "\n",
       "                                           Images_url Raring  \n",
       "0   https://m.media-amazon.com/images/I/71poFSdDs5...   4.2   \n",
       "1   https://m.media-amazon.com/images/I/71KCwNV6Mu...   4.2   \n",
       "2   https://m.media-amazon.com/images/I/71-Su4Wr0H...   4.2   \n",
       "3   https://m.media-amazon.com/images/I/81S-XYJlzT...   4.2   \n",
       "4   https://m.media-amazon.com/images/I/81B0HJigO-...   4.0   \n",
       "5   https://m.media-amazon.com/images/I/71os5DRhuS...   3.8   \n",
       "6   https://m.media-amazon.com/images/I/71geVdy6-O...   4.2   \n",
       "7   https://m.media-amazon.com/images/I/71os5DRhuS...   3.8   \n",
       "8   https://m.media-amazon.com/images/I/719tm7l723...   4.0   \n",
       "9   https://m.media-amazon.com/images/I/615CXlFtDD...   4.3   \n",
       "10  https://m.media-amazon.com/images/I/71F4jU7MRU...   4.2   \n",
       "11  https://m.media-amazon.com/images/I/71r69Y7BSe...   4.1   \n",
       "12  https://m.media-amazon.com/images/I/71QT7dSK4B...   3.8   \n",
       "13  https://m.media-amazon.com/images/I/71UAi2jwsN...   4.2   \n",
       "14  https://m.media-amazon.com/images/I/61uIgwiP90...   4.3   \n",
       "15  https://m.media-amazon.com/images/I/71Q3iSQAwA...   4.2   \n",
       "16  https://m.media-amazon.com/images/I/51GkJLzb9N...   3.8   \n",
       "17  https://m.media-amazon.com/images/I/713AhSUtbH...   4.4   \n",
       "18  https://m.media-amazon.com/images/I/718CklLKXm...   4.0   \n",
       "19  https://m.media-amazon.com/images/I/71MeL149KB...   4.2   \n",
       "20  https://m.media-amazon.com/images/I/71hgVYiuFX...   3.9   \n",
       "21  https://m.media-amazon.com/images/I/81di9YjMe-...   3.6   \n",
       "22  https://m.media-amazon.com/images/I/41+r5uIAAA...   4.0   "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is the complete code to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon and include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "page = requests.get('https://www.amazon.in/s?k=smartphone+under+20000&rh=n%3A976419031%2Cp_36%3A1318506031&dc&qid=1631345642&rnid=1318502031&ref=sr_nr_p_36_4')\n",
    "soup=BeautifulSoup(page.content)\n",
    "page\n",
    "\n",
    "titles = []\n",
    "for i in soup.find_all(\"h2\", class_=\"a-size-mini a-spacing-none a-color-base s-line-clamp-2\")[0:23]:\n",
    "    titles.append(i.text.split('|')[0])\n",
    "\n",
    "price=[] \n",
    "for i in soup.find_all('span',class_=\"a-price-whole\")[0:23]: \n",
    "    price.append(i.text)\n",
    "\n",
    "images=[] \n",
    "for  i in soup.find_all(\"img\", class_=\"s-image\")[0:23]:\n",
    "    images.append(i['srcset'])\n",
    "\n",
    "ratings=[] \n",
    "for i in soup.find_all('span',class_=\"a-icon-alt\")[0:23]: \n",
    "    ratings.append(i.text.split('out')[0])\n",
    "\n",
    "(len(titles),len(price),len(images),len(ratings))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Product_name':titles,'Price':price,'Images_url':images,'Raring':ratings})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6f144eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House_Title</th>\n",
       "      <th>Location</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Hebba...</td>\n",
       "      <td>Independent House, Bangalore - Hosur Road, Nea...</td>\n",
       "      <td>1,800 sqft</td>\n",
       "      <td>77,374/MonthEstimated EMI</td>\n",
       "      <td>1.35 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Nisarga Residenc...</td>\n",
       "      <td>Nisarga Residency  Near Thali Resturant, Anant...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>45,851/MonthEstimated EMI</td>\n",
       "      <td>80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...</td>\n",
       "      <td>Sobha Silicon Oasis Naganathapura, Rayasandra ...</td>\n",
       "      <td>1,879 sqft</td>\n",
       "      <td>9,170/MonthEstimated EMI</td>\n",
       "      <td>16 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK For Sale  In Daadys Garden In Electronic...</td>\n",
       "      <td>Daadys Garden  Kammasandra Rd, Kammasandra, El...</td>\n",
       "      <td>2,600 sqft</td>\n",
       "      <td>85,971/MonthEstimated EMI</td>\n",
       "      <td>1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In , Electronic City</td>\n",
       "      <td>Standalone Building, 16th Cross Road Neeladri ...</td>\n",
       "      <td>2,000 sqft</td>\n",
       "      <td>39,546/MonthEstimated EMI</td>\n",
       "      <td>69 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK Flat  For Sale  In Hosa Road, Parappana ...</td>\n",
       "      <td>Standalone Building, 11th cross.anjanadri lay ...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>71,643/MonthEstimated EMI</td>\n",
       "      <td>1.25 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, surya nagar face 1Explore N...</td>\n",
       "      <td>3,000 sqft</td>\n",
       "      <td>1.43 Lacs/MonthEstimated EMI</td>\n",
       "      <td>2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, Hosur Rd,Near Infosys Limit...</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>42,985/MonthEstimated EMI</td>\n",
       "      <td>75 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>Gopalan Gardenia  Gopalan gardenia, Veerasandr...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>68,777/MonthEstimated EMI</td>\n",
       "      <td>1.2 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK For Sale  In Gpr Royale In Gpr Royale</td>\n",
       "      <td>6th CrossExplore Nearby</td>\n",
       "      <td>3,100 sqft</td>\n",
       "      <td>85,971/MonthEstimated EMI</td>\n",
       "      <td>1.5 Crores</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         House_Title  \\\n",
       "0  4 BHK In Independent House  For Sale  In Hebba...   \n",
       "1  4 BHK Apartment  For Sale  In Nisarga Residenc...   \n",
       "2  4 BHK Flat  For Sale  In Sobha Silicon Oasis  ...   \n",
       "3  4 BHK For Sale  In Daadys Garden In Electronic...   \n",
       "4        4 BHK Flat  For Sale  In , Electronic City    \n",
       "5  4 BHK Flat  For Sale  In Hosa Road, Parappana ...   \n",
       "6  4 BHK In Independent House  For Sale  In Elect...   \n",
       "7  4 BHK In Independent House  For Sale  In Elect...   \n",
       "8  4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "9       4 BHK For Sale  In Gpr Royale In Gpr Royale    \n",
       "\n",
       "                                            Location        Area  \\\n",
       "0  Independent House, Bangalore - Hosur Road, Nea...  1,800 sqft   \n",
       "1  Nisarga Residency  Near Thali Resturant, Anant...  2,000 sqft   \n",
       "2  Sobha Silicon Oasis Naganathapura, Rayasandra ...  1,879 sqft   \n",
       "3  Daadys Garden  Kammasandra Rd, Kammasandra, El...  2,600 sqft   \n",
       "4  Standalone Building, 16th Cross Road Neeladri ...  2,000 sqft   \n",
       "5  Standalone Building, 11th cross.anjanadri lay ...  3,000 sqft   \n",
       "6  Independent House, surya nagar face 1Explore N...  3,000 sqft   \n",
       "7  Independent House, Hosur Rd,Near Infosys Limit...  1,200 sqft   \n",
       "8  Gopalan Gardenia  Gopalan gardenia, Veerasandr...  2,650 sqft   \n",
       "9                            6th CrossExplore Nearby  3,100 sqft   \n",
       "\n",
       "                            EMI        Price  \n",
       "0     77,374/MonthEstimated EMI  1.35 Crores  \n",
       "1     45,851/MonthEstimated EMI      80 Lacs  \n",
       "2      9,170/MonthEstimated EMI      16 Lacs  \n",
       "3     85,971/MonthEstimated EMI   1.5 Crores  \n",
       "4     39,546/MonthEstimated EMI      69 Lacs  \n",
       "5     71,643/MonthEstimated EMI  1.25 Crores  \n",
       "6  1.43 Lacs/MonthEstimated EMI   2.5 Crores  \n",
       "7     42,985/MonthEstimated EMI      75 Lacs  \n",
       "8     68,777/MonthEstimated EMI   1.2 Crores  \n",
       "9     85,971/MonthEstimated EMI   1.5 Crores  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q7. Write a python program to scrape house details from mentioned url. It should include house title, location, area, emi and price https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "page = requests.get('https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "page\n",
    "\n",
    "# House title\n",
    "title = soup.find('h2',class_=\"heading-6 font-semi-bold nb__1AShY\")\n",
    "title.text\n",
    "\n",
    "# Location\n",
    "loc = soup.find('div',class_=\"nb__35Ol7\")\n",
    "loc.text.split(',')[1]\n",
    "\n",
    "\n",
    "# Area in square feet\n",
    "area = soup.find('div',class_=\"nb__3oNyC\")\n",
    "area.text\n",
    "\n",
    "\n",
    "# EMI\n",
    "emi = soup.find('div',class_=\"nb__17R6o\")\n",
    "emi.text.split('₹')[2]\n",
    "\n",
    "\n",
    "# Price\n",
    "emi = soup.find('div',class_=\"nb__17R6o\")\n",
    "emi.text.split('₹')[3]\n",
    "\n",
    "\n",
    "titles=[]\n",
    "\n",
    "for i in soup.find_all(\"h2\", class_=\"heading-6 font-semi-bold nb__1AShY\"):\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles\n",
    "\n",
    "\n",
    "location=[] \n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"nb__35Ol7\"):\n",
    "    location.append(i.text)\n",
    "     \n",
    "location\n",
    "\n",
    "\n",
    "area=[] \n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"nb__3oNyC\"):\n",
    "    area.append(i.text)\n",
    "     \n",
    "area\n",
    "\n",
    "\n",
    "emi=[] \n",
    "\n",
    "for i in soup.find_all('div',class_=\"nb__17R6o\"):\n",
    "    emi.append(i.text.split('₹')[2])\n",
    "     \n",
    "emi\n",
    "\n",
    "\n",
    "price=[] \n",
    "\n",
    "for i in soup.find_all('div',class_=\"nb__17R6o\"):\n",
    "    price.append(i.text.split('₹')[3])\n",
    "     \n",
    "price\n",
    "\n",
    "(len(titles),len(location),len(area),len(emi),len(price))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'House_Title':titles,'Location':location,'Area':area,'EMI':emi,'Price':price})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4581a465",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Resturent_name</th>\n",
       "      <th>Cuisine</th>\n",
       "      <th>Location</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Images_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Castle BarbequeConnaught Place, Central Delhi</td>\n",
       "      <td>Chinese, North Indian</td>\n",
       "      <td>Connaught Place, Central Delhi</td>\n",
       "      <td>3.4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...</td>\n",
       "      <td>North Indian, Barbecue, Italian, Asian</td>\n",
       "      <td>3CS Mall,Lajpat Nagar - 3, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Castle BarbequePacific Mall,Tagore Garden, Wes...</td>\n",
       "      <td>North Indian, Chinese</td>\n",
       "      <td>Pacific Mall,Tagore Garden, West Delhi</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Barbeque CompanyGardens Galleria,Sector 38...</td>\n",
       "      <td>Barbecue, Chinese, Mughlai, North Indian</td>\n",
       "      <td>Gardens Galleria,Sector 38A, Noida</td>\n",
       "      <td>4.1</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cafe KnoshThe Leela Ambience Convention Hotel,...</td>\n",
       "      <td>Multi-Cuisine, North Indian, Italian, Contine...</td>\n",
       "      <td>The Leela Ambience Convention Hotel,Shahdara, ...</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>India GrillHilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>North Indian, Italian, Oriental</td>\n",
       "      <td>Hilton Garden Inn,Saket, South Delhi</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...</td>\n",
       "      <td>Barbecue, North Indian</td>\n",
       "      <td>Taurus Sarovar Portico,Mahipalpur, South Delhi</td>\n",
       "      <td>3.7</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Monarch - Bar Be Que VillageIndirapuram Ha...</td>\n",
       "      <td>North Indian, Chinese, Fast Food</td>\n",
       "      <td>Indirapuram Habitat Centre,Indirapuram, Ghaziabad</td>\n",
       "      <td>3.9</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>World CafeVibe by The Lalit Traveller,Sector 3...</td>\n",
       "      <td>North Indian, Chinese, Continental</td>\n",
       "      <td>Vibe by The Lalit Traveller,Sector 35, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Indian Grill RoomSuncity Business Tower,Golf C...</td>\n",
       "      <td>North Indian, Mughlai, Barbecue</td>\n",
       "      <td>Suncity Business Tower,Golf Course Road, Gurgaon</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mad 4 Bar B QueSector 29, Faridabad</td>\n",
       "      <td>North Indian, Mughlai</td>\n",
       "      <td>Sector 29, Faridabad</td>\n",
       "      <td>3.8</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Barbeque 29NIT, Faridabad</td>\n",
       "      <td>Barbecue, Chinese, North Indian</td>\n",
       "      <td>NIT, Faridabad</td>\n",
       "      <td>4.3</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GlasshouseDoubleTree By Hilton Gurugram Baani ...</td>\n",
       "      <td>Multi-Cuisine, Asian, European, Italian, Nort...</td>\n",
       "      <td>DoubleTree By Hilton Gurugram Baani Square,Sec...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://im1.dineout.co.in/images/uploads/resta...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Resturent_name  \\\n",
       "0       Castle BarbequeConnaught Place, Central Delhi   \n",
       "1   Jungle Jamboree3CS Mall,Lajpat Nagar - 3, Sout...   \n",
       "2   Castle BarbequePacific Mall,Tagore Garden, Wes...   \n",
       "3   The Barbeque CompanyGardens Galleria,Sector 38...   \n",
       "4   Cafe KnoshThe Leela Ambience Convention Hotel,...   \n",
       "5     India GrillHilton Garden Inn,Saket, South Delhi   \n",
       "6   Delhi BarbequeTaurus Sarovar Portico,Mahipalpu...   \n",
       "7   The Monarch - Bar Be Que VillageIndirapuram Ha...   \n",
       "8   World CafeVibe by The Lalit Traveller,Sector 3...   \n",
       "9   Indian Grill RoomSuncity Business Tower,Golf C...   \n",
       "10                Mad 4 Bar B QueSector 29, Faridabad   \n",
       "11                          Barbeque 29NIT, Faridabad   \n",
       "12  GlasshouseDoubleTree By Hilton Gurugram Baani ...   \n",
       "\n",
       "                                              Cuisine  \\\n",
       "0                               Chinese, North Indian   \n",
       "1              North Indian, Barbecue, Italian, Asian   \n",
       "2                               North Indian, Chinese   \n",
       "3            Barbecue, Chinese, Mughlai, North Indian   \n",
       "4    Multi-Cuisine, North Indian, Italian, Contine...   \n",
       "5                    North Indian, Italian, Oriental    \n",
       "6                              Barbecue, North Indian   \n",
       "7                    North Indian, Chinese, Fast Food   \n",
       "8                  North Indian, Chinese, Continental   \n",
       "9                     North Indian, Mughlai, Barbecue   \n",
       "10                              North Indian, Mughlai   \n",
       "11                    Barbecue, Chinese, North Indian   \n",
       "12   Multi-Cuisine, Asian, European, Italian, Nort...   \n",
       "\n",
       "                                             Location Ratings  \\\n",
       "0                      Connaught Place, Central Delhi     3.4   \n",
       "1              3CS Mall,Lajpat Nagar - 3, South Delhi     3.9   \n",
       "2              Pacific Mall,Tagore Garden, West Delhi       4   \n",
       "3                  Gardens Galleria,Sector 38A, Noida     4.1   \n",
       "4   The Leela Ambience Convention Hotel,Shahdara, ...     4.3   \n",
       "5                Hilton Garden Inn,Saket, South Delhi     3.9   \n",
       "6      Taurus Sarovar Portico,Mahipalpur, South Delhi     3.7   \n",
       "7   Indirapuram Habitat Centre,Indirapuram, Ghaziabad     3.9   \n",
       "8    Vibe by The Lalit Traveller,Sector 35, Faridabad     4.3   \n",
       "9    Suncity Business Tower,Golf Course Road, Gurgaon     4.3   \n",
       "10                               Sector 29, Faridabad     3.8   \n",
       "11                                     NIT, Faridabad     4.3   \n",
       "12  DoubleTree By Hilton Gurugram Baani Square,Sec...       4   \n",
       "\n",
       "                                           Images_url  \n",
       "0   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "1   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "2   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "3   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "4   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "5   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "6   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "7   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "8   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "9   https://im1.dineout.co.in/images/uploads/resta...  \n",
       "10  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "11  https://im1.dineout.co.in/images/uploads/resta...  \n",
       "12  https://im1.dineout.co.in/images/uploads/resta...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q8. Write a python program to scrape mentioned details from ‘https://www.dineout.co.in/delhi-restaurants/buffet-special’ :\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "page = requests.get('https://www.dineout.co.in/delhi-restaurants/buffet-special')\n",
    "\n",
    "soup=BeautifulSoup(page.content)\n",
    "\n",
    "\n",
    "#<i> Restaurant name\n",
    "rst_nm = soup.find('div',class_=\"restnt-info cursor\")\n",
    "rst_nm.text\n",
    "\n",
    "\n",
    "#<ii> Cuisine\n",
    "csn=soup.find('span',class_=\"double-line-ellipsis\")\n",
    "csn.text.split('|')[1]\n",
    "\n",
    "#<iii> Location\n",
    "loc=soup.find('div',class_=\"restnt-loc ellipsis\")\n",
    "loc.text\n",
    "\n",
    "#<iv> Ratings\n",
    "rate=soup.find('div',class_=\"restnt-rating rating-3\")\n",
    "rate.text\n",
    "\n",
    "#<v> Image URL\n",
    "img=soup.find(\"img\", class_=\"no-img\")\n",
    "img['data-src']\n",
    "\n",
    "\n",
    "titles=[]\n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-info cursor\"):\n",
    "    titles.append(i.text)\n",
    "    \n",
    "titles\n",
    "\n",
    "\n",
    "cuisine=[]\n",
    "\n",
    "for i in soup.find_all('span',class_=\"double-line-ellipsis\"):\n",
    "    cuisine.append(i.text.split('|')[1])\n",
    "    \n",
    "cuisine\n",
    "\n",
    "\n",
    "location=[] \n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-loc ellipsis\"):\n",
    "    location.append(i.text)\n",
    "     \n",
    "location\n",
    "\n",
    "rating=[]\n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-3\"):\n",
    "\n",
    "    rating.append(i.text)\n",
    "\n",
    "for i in soup.find_all(\"div\", class_=\"restnt-rating rating-4\"):\n",
    "\n",
    "    rating.append(i.text)\n",
    "\n",
    "rating\n",
    "\n",
    "\n",
    "images=[] \n",
    "\n",
    "for  i in soup.find_all(\"img\", class_=\"no-img\"):\n",
    "\n",
    "    images.append(i['data-src'])\n",
    "\n",
    "images\n",
    "\n",
    "\n",
    "(len(titles),len(cuisine),len(location),len(rating),len(images))\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Resturent_name':titles,'Cuisine':cuisine,'Location':location,'Ratings':rating,'Images_url':images,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "07f32c1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hour</th>\n",
       "      <th>Tempreature</th>\n",
       "      <th>Weather_condition</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Pressure</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18:00</td>\n",
       "      <td>26°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17:30</td>\n",
       "      <td>26°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17:00</td>\n",
       "      <td>26°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>58%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16:30</td>\n",
       "      <td>27°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16:00</td>\n",
       "      <td>27°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>15:30</td>\n",
       "      <td>28°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>48%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>15:00</td>\n",
       "      <td>28°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>45%</td>\n",
       "      <td>1013 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14:30</td>\n",
       "      <td>28°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>45%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14:00</td>\n",
       "      <td>28°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>48%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13:30</td>\n",
       "      <td>28°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>48%</td>\n",
       "      <td>1014 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13:00</td>\n",
       "      <td>27°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>51%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12:30</td>\n",
       "      <td>27°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>51%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12:00</td>\n",
       "      <td>26°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1016 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>11:30</td>\n",
       "      <td>25°C</td>\n",
       "      <td>Mist</td>\n",
       "      <td>54%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>11:00</td>\n",
       "      <td>23°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>53%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10:30</td>\n",
       "      <td>23°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>53%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10:00</td>\n",
       "      <td>22°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>57%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>09:30</td>\n",
       "      <td>22°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>57%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>09:00</td>\n",
       "      <td>21°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>60%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>08:30</td>\n",
       "      <td>20°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>64%</td>\n",
       "      <td>1017 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>08:00</td>\n",
       "      <td>19°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>68%</td>\n",
       "      <td>1016 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>07:30</td>\n",
       "      <td>19°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>68%</td>\n",
       "      <td>1016 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>06:00</td>\n",
       "      <td>19°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>68%</td>\n",
       "      <td>1016 hPa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>05:30</td>\n",
       "      <td>19°C</td>\n",
       "      <td>Widespread Fog</td>\n",
       "      <td>73%</td>\n",
       "      <td>1015 hPa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Hour Tempreature Weather_condition Humidity  Pressure\n",
       "0   18:00        26°C              Mist      54%  1013 hPa\n",
       "1   17:30        26°C              Mist      54%  1013 hPa\n",
       "2   17:00        26°C              Mist      58%  1013 hPa\n",
       "3   16:30        27°C              Mist      54%  1013 hPa\n",
       "4   16:00        27°C              Mist      54%  1013 hPa\n",
       "5   15:30        28°C              Mist      48%  1013 hPa\n",
       "6   15:00        28°C              Mist      45%  1013 hPa\n",
       "7   14:30        28°C              Mist      45%  1014 hPa\n",
       "8   14:00        28°C              Mist      48%  1014 hPa\n",
       "9   13:30        28°C              Mist      48%  1014 hPa\n",
       "10  13:00        27°C              Mist      51%  1015 hPa\n",
       "11  12:30        27°C              Mist      51%  1015 hPa\n",
       "12  12:00        26°C              Mist      54%  1016 hPa\n",
       "13  11:30        25°C              Mist      54%  1017 hPa\n",
       "14  11:00        23°C    Widespread Fog      53%  1017 hPa\n",
       "15  10:30        23°C    Widespread Fog      53%  1017 hPa\n",
       "16  10:00        22°C    Widespread Fog      57%  1017 hPa\n",
       "17  09:30        22°C    Widespread Fog      57%  1017 hPa\n",
       "18  09:00        21°C    Widespread Fog      60%  1017 hPa\n",
       "19  08:30        20°C    Widespread Fog      64%  1017 hPa\n",
       "20  08:00        19°C    Widespread Fog      68%  1016 hPa\n",
       "21  07:30        19°C    Widespread Fog      68%  1016 hPa\n",
       "22  06:00        19°C    Widespread Fog      68%  1016 hPa\n",
       "23  05:30        19°C    Widespread Fog      73%  1015 hPa"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q9. Write a python program to scrape weather details for last 24 hours from ‘https://en.tutiempo.net/delhi.html?data=last-24- hours’ :\n",
    "#i) Hour\n",
    "#ii) Temperature\n",
    "#iii) Wind\n",
    "#iv) Weather condition\n",
    "#v) Humidity\n",
    "#vi) Pressure\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#send get request to the webpage server to get the source code of the page\n",
    "url = \"https://en.tutiempo.net/delhi.html?data=last-24-hours\"\n",
    "page9 = requests.get(url)\n",
    "# see content in page5\n",
    "soup9 = BeautifulSoup(page9.content)\n",
    "\n",
    "hour = [] \n",
    "temperature=[] \n",
    "wind = [] \n",
    "weather_condition= []\n",
    "humidity = [] \n",
    "pressure= [] \n",
    "new_list = [] \n",
    "\n",
    "for i in soup9.find_all(\"td\",class_='t Temp')[0:24]:\n",
    "    temperature.append(i.text)\n",
    "    if i.previous_sibling.previous_sibling is not None:\n",
    "        hour.append(i.previous_sibling.previous_sibling.text)\n",
    "    else:\n",
    "        hour.append(' ')\n",
    "\n",
    "for i in soup9.find_all(\"td\",class_='wind')[0:24]:\n",
    "    wind.append(i.text)\n",
    "    if i.previous_sibling.previous_sibling is not None:\n",
    "        weather_condition.append(i.previous_sibling.previous_sibling.text)\n",
    "    else:\n",
    "        weather_condition.append(' ')\n",
    "for i in soup9.find_all(\"td\",class_='hr')[0:24]:\n",
    "    humidity.append(i.text)\n",
    "    \n",
    "for i in soup9.find_all(\"td\",class_='prob')[0:24]:\n",
    "    pressure.append(i.text)\n",
    "pressure\n",
    "\n",
    "\n",
    "(len(hour),len(temperature),len(weather_condition),len(humidity),len(pressure))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Hour':hour,'Tempreature':temperature,'Weather_condition':weather_condition,'Humidity':humidity,'Pressure':pressure,})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94d86aa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Monument_name</th>\n",
       "      <th>Description</th>\n",
       "      <th>Image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Taj Mahal, Agra</td>\n",
       "      <td>Enlisted in the Seven Wonders of the World, Th...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Golden Temple (Harmandir Sahib), Amritsar</td>\n",
       "      <td>The holiest shrine and pilgrimage place locate...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Meenakshi Temple, Madurai</td>\n",
       "      <td>Meenakshi Temple is situated on the Southern b...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mysore Palace, Mysore</td>\n",
       "      <td>The Mysore Palace is a famous historical monum...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gateway of India, Mumbai</td>\n",
       "      <td>Even though Mumbai is famous for its Bollywood...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Red Fort, New Delhi</td>\n",
       "      <td>Declared as the UNESCO’s World Heritage Site, ...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hawa Mahal, Jaipur</td>\n",
       "      <td>Explore a blend of beauty and Rajasthan cultur...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Qutub Minar, New Delhi</td>\n",
       "      <td>Discover one of the tallest towers in the worl...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sanchi Stupa, Sanchi</td>\n",
       "      <td>The beautiful and massive dome, Sanchi Stupa a...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Charminar, Hyderabad</td>\n",
       "      <td>No visit to Hyderabad should be complete witho...</td>\n",
       "      <td>http://www.puredestinations.co.uk/wp-content/u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Monument_name  \\\n",
       "0                             Taj Mahal, Agra   \n",
       "1  Golden Temple (Harmandir Sahib), Amritsar    \n",
       "2                   Meenakshi Temple, Madurai   \n",
       "3                       Mysore Palace, Mysore   \n",
       "4                    Gateway of India, Mumbai   \n",
       "5                         Red Fort, New Delhi   \n",
       "6                          Hawa Mahal, Jaipur   \n",
       "7                      Qutub Minar, New Delhi   \n",
       "8                        Sanchi Stupa, Sanchi   \n",
       "9                        Charminar, Hyderabad   \n",
       "\n",
       "                                         Description  \\\n",
       "0  Enlisted in the Seven Wonders of the World, Th...   \n",
       "1  The holiest shrine and pilgrimage place locate...   \n",
       "2  Meenakshi Temple is situated on the Southern b...   \n",
       "3  The Mysore Palace is a famous historical monum...   \n",
       "4  Even though Mumbai is famous for its Bollywood...   \n",
       "5  Declared as the UNESCO’s World Heritage Site, ...   \n",
       "6  Explore a blend of beauty and Rajasthan cultur...   \n",
       "7  Discover one of the tallest towers in the worl...   \n",
       "8  The beautiful and massive dome, Sanchi Stupa a...   \n",
       "9  No visit to Hyderabad should be complete witho...   \n",
       "\n",
       "                                           Image_url  \n",
       "0  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "1  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "2  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "3  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "4  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "5  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "6  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "7  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "8  http://www.puredestinations.co.uk/wp-content/u...  \n",
       "9  http://www.puredestinations.co.uk/wp-content/u...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10. Write a python program to scrape monument name, monument description, image url about top 10 monuments from 'https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/'\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "#Fatching content of page that has top 10 famous monuments in india\n",
    "url='https://www.puredestinations.co.uk/top-10-famous-monuments-to-visit-in-india/' \n",
    "\n",
    "response = requests.get(url) #in order to work with html we need to get it as string\n",
    "soup= BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "title = soup.find('h3',class_=\"title title--heading\")\n",
    "\n",
    "#Scraping data\n",
    "data = soup.find_all('div', class_=\"blog--single__content column--3-4 u-spacing-third\")\n",
    "temp=[]\n",
    "for i in data:\n",
    "    for j in i.find_all('p'):\n",
    "        t = j.text.replace('\\n', '') # only extracting data\n",
    "        temp.append(t)\n",
    "        \n",
    "name=[] #Monument name\n",
    "for i in range(1,30,3):\n",
    "    name.append(temp[i])\n",
    "    \n",
    "description=[] #Monument Description\n",
    "for i in range(2,30,3):\n",
    "    description.append(temp[i])\n",
    "    \n",
    "images=[] #Scraping all image url\n",
    "for i in soup.find_all('img'):\n",
    "    images.append(i['src'])\n",
    "image_url=[]\n",
    "for i in range(6,26,2):\n",
    "    image_url.append(images[i])\n",
    "\n",
    "    \n",
    "\n",
    "(len(name),len(description),len(image_url))\n",
    "\n",
    "import pandas as pd\n",
    "df=pd.DataFrame({'Monument_name':name,'Description':description,'Image_url':image_url})\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50783a61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
